<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Add a multi-dimensional state variable · SDDP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../logo.ico" rel="icon" type="image/x-icon"/></head><body><nav class="toc"><a href="../../"><img class="logo" src="../../assets/logo.png" alt="SDDP.jl logo"/></a><h1>SDDP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">How-to guides</span><ul><li class="current"><a class="toctext" href>Add a multi-dimensional state variable</a><ul class="internal"></ul></li><li><a class="toctext" href="../add_a_risk_measure/">Add a risk measure</a></li><li><a class="toctext" href="../add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="toctext" href="../add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li><a class="toctext" href="../choose_a_stopping_rule/">Choose a stopping rule</a></li><li><a class="toctext" href="../create_a_general_policy_graph/">Create a general policy graph</a></li><li><a class="toctext" href="../debug_a_model/">Debug a model</a></li><li><a class="toctext" href="../improve_computational_performance/">Improve computational performance</a></li><li><a class="toctext" href="../simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li><li><a class="toctext" href="../upgrade_from_the_old_sddp/">Upgrade from the old SDDP.jl</a></li></ul></li><li><span class="toctext">Tutorials</span><ul><li><a class="toctext" href="../../tutorial/01_first_steps/">Basic I: first steps</a></li><li><a class="toctext" href="../../tutorial/02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="toctext" href="../../tutorial/03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="toctext" href="../../tutorial/04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="toctext" href="../../tutorial/05_plotting/">Basic V: plotting</a></li><li><a class="toctext" href="../../tutorial/06_warnings/">Basic VI: words of warning</a></li><li><a class="toctext" href="../../tutorial/11_objective_states/">Advanced I: objective states</a></li><li><a class="toctext" href="../../tutorial/12_belief_states/">Advanced II: belief states</a></li><li><a class="toctext" href="../../tutorial/13_integrality/">Advanced III: integrality</a></li></ul></li><li><span class="toctext">Examples</span><ul><li><a class="toctext" href="../../examples/the_farmers_problem/">The farmer&#39;s problem</a></li></ul></li><li><a class="toctext" href="../../apireference/">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li>How-to guides</li><li><a href>Add a multi-dimensional state variable</a></li></ul><a class="edit-page" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/guides/add_a_multidimensional_state_variable.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Add a multi-dimensional state variable</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Add-a-multi-dimensional-state-variable-1" href="#Add-a-multi-dimensional-state-variable-1">Add a multi-dimensional state variable</a></h1><p>Just like normal JuMP variables, it is possible to create containers of state variables.</p><pre><code class="language-julia-repl">julia&gt; model = SDDP.LinearPolicyGraph(
           stages=1, lower_bound = 0, optimizer = with_optimizer(GLPK.Optimizer)
       ) do subproblem, t
           # A scalar state variable.
           @variable(subproblem, x &gt;= 0, SDDP.State, initial_value = 0)
           println(&quot;Lower bound of outgoing x is: &quot;, JuMP.lower_bound(x.out))
           # A vector of state variables.
           @variable(subproblem, y[i = 1:2] &gt;= i, SDDP.State, initial_value = i)
           println(&quot;Lower bound of outgoing y[1] is: &quot;, JuMP.lower_bound(y[1].out))
           # A JuMP.Containers.DenseAxisArray of state variables.
           @variable(subproblem,
               z[i = 3:4, j = [:A, :B]] &gt;= i, SDDP.State, initial_value = i)
           println(&quot;Lower bound of outgoing z[3, :B] is: &quot;, JuMP.lower_bound(z[3, :B].out))
       end;
Lower bound of outgoing x is: 0.0
Lower bound of outgoing y[1] is: 1.0
Lower bound of outgoing z[3, :B] is: 3.0</code></pre><footer><hr/><a class="previous" href="../../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../add_a_risk_measure/"><span class="direction">Next</span><span class="title">Add a risk measure</span></a></footer></article></body></html>
