<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Debug a model · SDDP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../"><img class="logo" src="../../assets/logo.png" alt="SDDP.jl logo"/></a><h1>SDDP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">How-to guides</span><ul><li><a class="toctext" href="../risk/">Add a risk measure</a></li><li><a class="toctext" href="../stopping_rules/">Choose a stopping rule</a></li><li><a class="toctext" href="../generic_graphs/">Create a general policy graph</a></li><li class="current"><a class="toctext" href>Debug a model</a><ul class="internal"><li><a class="toctext" href="#Writing-subproblems-to-file-1">Writing subproblems to file</a></li><li><a class="toctext" href="#Solve-the-determinstic-equivalent-1">Solve the determinstic equivalent</a></li></ul></li><li><a class="toctext" href="../performance/">Improve computational performance</a></li><li><a class="toctext" href="../multidim_states/">-</a></li><li><a class="toctext" href="../multivariate_noise/">-</a></li><li><a class="toctext" href="../noise_constraint/">Add noise in the constraint matrix</a></li><li><a class="toctext" href="../upgrading_guide/">Upgrade from the old SDDP.jl</a></li></ul></li><li><span class="toctext">Tutorials</span><ul><li><span class="toctext">Basic</span><ul><li><a class="toctext" href="../../tutorial/01_first_steps/">Basic I: first steps</a></li><li><a class="toctext" href="../../tutorial/02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="toctext" href="../../tutorial/03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="toctext" href="../../tutorial/04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="toctext" href="../../tutorial/05_plotting/">Basic V: plotting</a></li><li><a class="toctext" href="../../tutorial/06_warnings/">Basic VI: words of warning</a></li></ul></li><li><span class="toctext">Advanced</span><ul><li><a class="toctext" href="../../tutorial/11_objective_states/">Advanced I: objective states</a></li><li><a class="toctext" href="../../tutorial/12_belief_states/">Advanced II: belief states</a></li><li><a class="toctext" href="../../tutorial/13_integrality/">Advanced III: integrality</a></li></ul></li></ul></li><li><span class="toctext">Examples</span><ul><li><a class="toctext" href="../../examples/the_farmers_problem/">The farmer&#39;s problem</a></li></ul></li><li><a class="toctext" href="../../apireference/">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li>How-to guides</li><li><a href>Debug a model</a></li></ul><a class="edit-page" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/guides/debugging.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Debug a model</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Debug-a-model-1" href="#Debug-a-model-1">Debug a model</a></h1><p>Building multistage stochastic programming models is hard. There are a lot of different pieces that need to be put together, and we typically have no idea of the optimal policy, so it can be hard (impossible?) to validate the solution.</p><p>That said, here are a few tips to verify and validate models built using <code>SDDP.jl</code>.</p><h2><a class="nav-anchor" id="Writing-subproblems-to-file-1" href="#Writing-subproblems-to-file-1">Writing subproblems to file</a></h2><p>The first step to debug a model is to write out the subproblems to a file in order to check that you are actually building what you think you are building.</p><p>This can be achieved with the help of two functions: <a href="../../apireference/#SDDP.parameterize"><code>SDDP.parameterize</code></a> and <a href="../../apireference/#SDDP.write_subproblem_to_file"><code>SDDP.write_subproblem_to_file</code></a>. The first lets you parameterize a node given a noise, and the second writes out the subproblem to a file.</p><p>Here is an example model:</p><pre><code class="language-julia">using SDDP, GLPK

model = SDDP.LinearPolicyGraph(
            stages = 2,
            lower_bound = 0.0,
            optimizer = with_optimizer(GLPK.Optimizer),
            direct_mode = false
        ) do subproblem, t
    @variable(subproblem, x, SDDP.State, initial_value = 1)
    @variable(subproblem, y)
    @constraint(subproblem, balance, x.in == x.out + y)
    SDDP.parameterize(subproblem, [1.1, 2.2]) do ω
        @stageobjective(subproblem, ω * x.out)
        JuMP.fix(y, ω)
    end
end

# output

A policy graph with 2 nodes.
 Node indices: 1, 2</code></pre><p>Initially, <code>model</code> hasn&#39;t been parameterized with a concrete realizations of <code>ω</code>. Let&#39;s do so now by parameterizing the first subproblem with <code>ω=1.1</code>.</p><pre><code class="language-julia-repl">julia&gt; SDDP.parameterize(model[1], 1.1)</code></pre><p>Easy! To parameterize the second stage problem, we would have used <code>model[2]</code>.</p><p>Now to write out the problem to a file. We&#39;ll get a few warnings because some variables and constraints don&#39;t have names. They don&#39;t matter, so ignore them.</p><pre><code class="language-julia-repl">julia&gt; SDDP.write_subproblem_to_file(model[1], &quot;subproblem&quot;, format=:lp)
</code></pre><p>We can check the file by reading it back in again.</p><pre><code class="language-julia-repl">julia&gt; read(&quot;subproblem.lp&quot;) |&gt; String |&gt; print
minimize
obj: 1.1 x_out + 1 x2
subject to
balance: 1 x_in - 1 x_out - 1 y = 0
Bounds
x2 &gt;= 0
y = 1.1
End</code></pre><p>It is easy to see that <code>ω</code> has been set in the objective, and as the fixed value for <code>y</code>.</p><p>It is also possible to parameterize the subproblems using values for <code>ω</code> that are not in the original problem formulation.</p><pre><code class="language-julia-repl">julia&gt; SDDP.parameterize(model[1], 3.3)

julia&gt; SDDP.write_subproblem_to_file(model[1], &quot;subproblem&quot;, format=:lp)


julia&gt; read(&quot;subproblem.lp&quot;) |&gt; String |&gt; print
minimize
obj: 3.3 x_out + 1 x2
subject to
balance: 1 x_in - 1 x_out - 1 y = 0
Bounds
x2 &gt;= 0
y = 3.3
End

julia&gt; rm(&quot;subproblem.lp&quot;)  # Clean up.</code></pre><h2><a class="nav-anchor" id="Solve-the-determinstic-equivalent-1" href="#Solve-the-determinstic-equivalent-1">Solve the determinstic equivalent</a></h2><p>Sometimes, it can be helpful to solve the deterministic equivalent of a problem in order to obtain an exact solution to the problem. To obtain a JuMP model that represents the deterministic equivalent, use <a href="../../apireference/#SDDP.deterministic_equivalent"><code>SDDP.deterministic_equivalent</code></a>. The returned model is just a normal JuMP model. Use JuMP to optimize it and query the solution.</p><pre><code class="language-julia-repl">julia&gt; det_equiv = SDDP.deterministic_equivalent(model, with_optimizer(GLPK.Optimizer))
A JuMP Model
Feasibility problem with:
Variables: 24
`GenericAffExpr{Float64,VariableRef}`-in-`MathOptInterface.EqualTo{Float64}`: 10 constraints
`VariableRef`-in-`MathOptInterface.EqualTo{Float64}`: 8 constraints
`VariableRef`-in-`MathOptInterface.GreaterThan{Float64}`: 6 constraints
`VariableRef`-in-`MathOptInterface.LessThan{Float64}`: 4 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: GLPK

julia&gt; optimize!(det_equiv)

julia&gt; objective_value(det_equiv)
-5.472500000000001</code></pre><div class="admonition warning"><div class="admonition-title">Warning</div><div class="admonition-text"><p>The determinstic equivalent scales poorly with problem size. Only use this on small problems!</p></div></div><footer><hr/><a class="previous" href="../generic_graphs/"><span class="direction">Previous</span><span class="title">Create a general policy graph</span></a><a class="next" href="../performance/"><span class="direction">Next</span><span class="title">Improve computational performance</span></a></footer></article></body></html>
