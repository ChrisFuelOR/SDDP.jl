<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Hydro-thermal scheduling · SDDP.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../logo.ico" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SDDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SDDP.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">How-to guides</span><ul><li><a class="tocitem" href="../../guides/add_a_multidimensional_state_variable/">Add a multi-dimensional state variable</a></li><li><a class="tocitem" href="../../guides/add_a_risk_measure/">Add a risk measure</a></li><li><a class="tocitem" href="../../guides/add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="tocitem" href="../../guides/add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li><a class="tocitem" href="../../guides/choose_a_stopping_rule/">Choose a stopping rule</a></li><li><a class="tocitem" href="../../guides/create_a_general_policy_graph/">Create a general policy graph</a></li><li><a class="tocitem" href="../../guides/debug_a_model/">Debug a model</a></li><li><a class="tocitem" href="../../guides/improve_computational_performance/">Improve computational performance</a></li><li><a class="tocitem" href="../../guides/simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li><li><a class="tocitem" href="../../guides/upgrade_from_the_old_sddp/">Upgrade from the old SDDP.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorial/01_first_steps/">Basic I: first steps</a></li><li><a class="tocitem" href="../../tutorial/02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="tocitem" href="../../tutorial/03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="tocitem" href="../../tutorial/04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="tocitem" href="../../tutorial/05_plotting/">Basic V: plotting</a></li><li><a class="tocitem" href="../../tutorial/06_warnings/">Basic VI: words of warning</a></li><li><a class="tocitem" href="../../tutorial/11_objective_states/">Advanced I: objective states</a></li><li><a class="tocitem" href="../../tutorial/12_belief_states/">Advanced II: belief states</a></li><li><a class="tocitem" href="../../tutorial/13_integrality/">Advanced III: integrality</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Hydro-thermal scheduling</a><ul class="internal"><li><a class="tocitem" href="#Problem-Description-1"><span>Problem Description</span></a></li><li><a class="tocitem" href="#Importing-packages-1"><span>Importing packages</span></a></li><li><a class="tocitem" href="#Constructing-the-policy-graph-1"><span>Constructing the policy graph</span></a></li><li><a class="tocitem" href="#Constructing-the-model-1"><span>Constructing the model</span></a></li><li><a class="tocitem" href="#Training-the-policy-1"><span>Training the policy</span></a></li><li><a class="tocitem" href="#Simulating-the-policy-1"><span>Simulating the policy</span></a></li><li><a class="tocitem" href="#Extracting-the-water-values-1"><span>Extracting the water values</span></a></li></ul></li><li><a class="tocitem" href="../the_farmers_problem/">The farmer&#39;s problem</a></li></ul></li><li><a class="tocitem" href="../../apireference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Hydro-thermal scheduling</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Hydro-thermal scheduling</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/examples/simple_hydro_thermal.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Hydro-thermal-scheduling-1"><a class="docs-heading-anchor" href="#Hydro-thermal-scheduling-1">Hydro-thermal scheduling</a><a class="docs-heading-anchor-permalink" href="#Hydro-thermal-scheduling-1" title="Permalink"></a></h1><h2 id="Problem-Description-1"><a class="docs-heading-anchor" href="#Problem-Description-1">Problem Description</a><a class="docs-heading-anchor-permalink" href="#Problem-Description-1" title="Permalink"></a></h2><p>In a hydro-thermal problem, the agent controls a hydro-electric generator and reservoir. Each time period, they need to choose a generation quantity from thermal <code>g_t</code>, and hydro <code>g_h</code>, in order to meed demand <code>w_d</code>, which is a stagewise-independent random variable. The state variable, <code>x</code>, is the quantity of water in the reservoir at the start of each time period, and it has a minimum level of 5 units and a maximum level of 15 units. We assume that there are 10 units of water in the reservoir at the start of time, so that <code>x_0 = 10</code>. The state-variable is connected through time by the water balance constraint: <code>x.out = x.in - g_t - s + w_i,</code> where <code>x.out</code> is the quantity of water at the end of the time period, <code>x.in</code> is the quantity of water at the start of the time period, <code>s</code> is the quantity of water spilled from the reservoir, and <code>w_i</code> is a stagewise-independent random variable that represents the inflow into the reservoir during the time period.</p><p>We assume that there are three stages, <code>t=1, 2, 3</code>, representing summer-fall, winter, and spring, and that we are solving this problem in an infinite-horizon setting with a discount factor of <code>0.95</code>.</p><p>In each stage, the agent incurs the cost of spillage, plus the cost of thermal generation. We assume that the cost of thermal generation is dependent on the stage <code>t = 1, 2, 3</code>, and that in each stage, <code>w</code> is drawn from the set <code>(w_i, w_d) = {(0, 7.5), (3, 5), (10, 2.5)}</code> with equal probability.</p><h2 id="Importing-packages-1"><a class="docs-heading-anchor" href="#Importing-packages-1">Importing packages</a><a class="docs-heading-anchor-permalink" href="#Importing-packages-1" title="Permalink"></a></h2><p>For this example, in addition to <code>SDDP</code>, we need <code>GLPK</code> as a solver and <code>Statisitics</code> to compute the mean of our simulations.</p><pre><code class="language-julia">using GLPK
using SDDP
using Statistics</code></pre><h2 id="Constructing-the-policy-graph-1"><a class="docs-heading-anchor" href="#Constructing-the-policy-graph-1">Constructing the policy graph</a><a class="docs-heading-anchor-permalink" href="#Constructing-the-policy-graph-1" title="Permalink"></a></h2><p>There are three stages in our problem, so we construct a linear policy graph with three stages using <a href="../../apireference/#SDDP.LinearGraph"><code>SDDP.LinearGraph</code></a>:</p><pre><code class="language-julia">graph = SDDP.LinearGraph(3)</code></pre><pre><code class="language-none">Root
 0
Nodes
 1
 2
 3
Arcs
 0 =&gt; 1 w.p. 1.0
 1 =&gt; 2 w.p. 1.0
 2 =&gt; 3 w.p. 1.0
</code></pre><p>Then, because we want to solve an infinite-horizon problem, we add an additional edge between node <code>3</code> and node <code>1</code> with probability <code>0.95</code>:</p><pre><code class="language-julia">SDDP.add_edge(graph, 3 =&gt; 1, 0.95)</code></pre><h2 id="Constructing-the-model-1"><a class="docs-heading-anchor" href="#Constructing-the-model-1">Constructing the model</a><a class="docs-heading-anchor-permalink" href="#Constructing-the-model-1" title="Permalink"></a></h2><p>Much of the macro code (i.e., lines starting with <code>@</code>) in the first part of the following should be familiar to users of JuMP.</p><p>Inside the <code>do-end</code> block (if this isn&#39;t familiar, see <a href="../../tutorial/01_first_steps/#What&#39;s-this-weird-do-syntax?-1">What&#39;s this weird <code>do</code> syntax?</a>), <code>sp</code> is a standard JuMP model, and <code>t</code> is an index for the state variable that will be called with <code>t = 1, 2, 3</code>.</p><p>The state variable <code>x</code>, constructed by passing the <code>SDDP.State</code> tag to <code>@variable</code> is actually a Julia struct with two fields: <code>x.in</code> and <code>x.out</code> corresponding to the incoming and outgoing state variables respectively. Both <code>x.in</code> and <code>x.out</code> are standard JuMP variables. The <code>initial_value</code> keyword provides the value of the state variable in the root node (i.e., <code>x_0</code>).</p><p>Compared to a JuMP model, one key difference is that we use <a href="../../apireference/#SDDP.@stageobjective"><code>@stageobjective</code></a> instead of <code>@objective</code>. The <a href="../../apireference/#SDDP.parameterize"><code>SDDP.parameterize</code></a> function takes a list of supports for <code>w</code> and parameterizes the JuMP model <code>sp</code> by setting the right-hand sides of the appropriate constraints (note how the constraints initially have a right-hand side of <code>0</code>). By default, it is assumed that the realizations have uniform probability, but a probability mass vector can also be provided.</p><pre><code class="language-julia">model = SDDP.PolicyGraph(
  graph, sense = :Min, lower_bound = 0.0, optimizer = with_optimizer(GLPK.Optimizer)
) do sp, t
  @variable(sp, 5 &lt;= x &lt;= 15, SDDP.State, initial_value = 10)
  @variable(sp, g_t &gt;= 0)
  @variable(sp, g_h &gt;= 0)
  @variable(sp, s &gt;= 0)
  @constraint(sp, balance, x.out - x.in + g_h + s == 0)
  @constraint(sp, demand, g_h + g_t == 0)
  @stageobjective(sp, s + t * g_t)
  SDDP.parameterize(sp, [[0, 7.5], [3, 5], [10, 2.5]]) do w
    set_normalized_rhs(balance, w[1])
    set_normalized_rhs(demand, w[2])
  end
end</code></pre><pre><code class="language-none">A policy graph with 3 nodes.
 Node indices: 1, 2, 3
</code></pre><h2 id="Training-the-policy-1"><a class="docs-heading-anchor" href="#Training-the-policy-1">Training the policy</a><a class="docs-heading-anchor-permalink" href="#Training-the-policy-1" title="Permalink"></a></h2><p>Once a model has been constructed, the next step is to train the policy. This can be achieved using <a href="../../apireference/#SDDP.train"><code>SDDP.train</code></a>. There are many options that can be passed, but <code>iteration_limit</code> terminates the training after the prescribed number of SDDP iterations.</p><pre><code class="language-julia">SDDP.train(model, iteration_limit = 100)</code></pre><pre><code class="language-none">------------------------------------------------------------------
                SDDP.jl (c) Oscar Dowson, 2017-20

Numerical stability report
  Non-zero Matrix range     [1e+00, 1e+00]
  Non-zero Objective range  [1e+00, 3e+00]
  Non-zero Bounds range     [5e+00, 2e+01]
  Non-zero RHS range        [3e+00, 1e+01]
No problems detected

Solver: serial mode

 Iteration    Simulation       Bound         Time (s)    Proc. ID
        1    1.295000e+02   5.092074e+01   2.831280e-01          1
        2    3.113768e+02   1.130659e+02   2.915211e-01          1
        3    2.056227e+02   1.346212e+02   2.981951e-01          1
        4    2.656857e+02   1.626704e+02   3.069031e-01          1
        5    2.431979e+02   1.776336e+02   3.162642e-01          1
        6    7.250000e+01   1.806705e+02   3.308101e-01          1
        7    4.826105e+01   1.823466e+02   3.326201e-01          1
        8    1.713546e+02   1.908043e+02   3.396621e-01          1
        9    2.012904e+02   1.974431e+02   3.468962e-01          1
       10    7.181995e+02   2.160342e+02   3.860121e-01          1
       11    1.954154e+02   2.179818e+02   3.938441e-01          1
       12    8.728339e+01   2.183737e+02   3.965330e-01          1
       13    1.879169e+02   2.195377e+02   4.065640e-01          1
       14    6.270295e+01   2.209714e+02   4.117820e-01          1
       15    6.459956e+02   2.254988e+02   4.529152e-01          1
       16    4.237051e+02   2.279233e+02   4.777710e-01          1
       17    3.932313e+02   2.296126e+02   5.166330e-01          1
       18    1.668456e+01   2.298947e+02   5.192721e-01          1
       19    2.063976e+02   2.301966e+02   5.306840e-01          1
       20    2.416397e+01   2.303076e+02   5.341990e-01          1
       21    3.617077e+01   2.305116e+02   5.368230e-01          1
       22    2.035989e+02   2.309847e+02   5.482640e-01          1
       23    8.006639e+01   2.310486e+02   5.518382e-01          1
       24    4.925694e+02   2.316732e+02   5.939701e-01          1
       25    6.154056e+02   2.328299e+02   6.445911e-01          1
       26    5.483602e+02   2.334043e+02   6.852741e-01          1
       27    1.193226e+02   2.336939e+02   6.978102e-01          1
       28    2.697087e+02   2.337974e+02   7.202752e-01          1
       29    5.290203e+02   2.344590e+02   7.723911e-01          1
       30    6.040468e+02   2.345876e+02   8.259301e-01          1
       31    3.624966e+02   2.349852e+02   8.642161e-01          1
       32    4.994980e+02   2.351224e+02   9.088950e-01          1
       33    2.744227e+01   2.351702e+02   9.114141e-01          1
       34    6.382018e+02   2.353124e+02   9.736922e-01          1
       35    3.886872e+01   2.353650e+02   9.798620e-01          1
       36    8.000000e+00   2.353687e+02   9.812381e-01          1
       37    2.177517e+02   2.354284e+02   1.000196e+00          1
       38    1.217882e+02   2.354860e+02   1.016210e+00          1
       39    2.500000e+00   2.354880e+02   1.017614e+00          1
       40    5.405260e+01   2.355189e+02   1.023865e+00          1
       41    1.750000e+01   2.355294e+02   1.025206e+00          1
       42    4.303968e+01   2.355393e+02   1.030073e+00          1
       43    4.637807e+01   2.355804e+02   1.035022e+00          1
       44    4.289919e+02   2.356192e+02   1.097420e+00          1
       45    5.508141e+02   2.357899e+02   1.165705e+00          1
       46    1.761898e+02   2.358164e+02   1.184358e+00          1
       47    3.319125e+02   2.358893e+02   1.217877e+00          1
       48    3.432109e+02   2.359696e+02   1.254492e+00          1
       49    2.547635e+02   2.359888e+02   1.285776e+00          1
       50    1.331271e+02   2.360327e+02   1.303248e+00          1
       51    4.513225e+02   2.360632e+02   1.344948e+00          1
       52    2.453830e+01   2.360654e+02   1.353215e+00          1
       53    5.898813e+02   2.361487e+02   1.438549e+00          1
       54    5.311813e+02   2.361657e+02   1.498511e+00          1
       55    1.079042e+00   2.361801e+02   1.500284e+00          1
       56    1.596552e+02   2.361885e+02   1.527878e+00          1
       57    2.544690e+02   2.362109e+02   1.554794e+00          1
       58    1.309058e+02   2.362225e+02   1.572391e+00          1
       59    7.256636e+02   2.362803e+02   1.655910e+00          1
       60    1.325137e+02   2.362868e+02   1.672921e+00          1
       61    1.230351e+02   2.362919e+02   1.685192e+00          1
       62    1.555841e+01   2.362933e+02   1.689975e+00          1
       63    3.186505e+02   2.362981e+02   1.736493e+00          1
       64    2.510364e+02   2.363144e+02   1.773193e+00          1
       65    1.813629e+02   2.363186e+02   1.814017e+00          1
       66    6.420012e+02   2.363367e+02   1.893563e+00          1
       67    2.435843e+02   2.363436e+02   1.918819e+00          1
       68    4.229648e+02   2.363550e+02   1.988461e+00          1
       69    2.500000e+00   2.363550e+02   1.990378e+00          1
       70    1.155758e+02   2.363580e+02   2.006383e+00          1
       71    1.885096e+02   2.363632e+02   2.034919e+00          1
       72    6.190276e+02   2.363710e+02   2.108120e+00          1
       73    1.350000e+01   2.363718e+02   2.111914e+00          1
       74    6.985561e+02   2.363886e+02   2.243483e+00          1
       75    6.372585e+02   2.363927e+02   2.323513e+00          1
       76    7.944364e+01   2.363961e+02   2.339042e+00          1
       77    1.750000e+01   2.363962e+02   2.341208e+00          1
       78    4.056775e+01   2.363965e+02   2.351105e+00          1
       79    1.335187e+02   2.363967e+02   2.368685e+00          1
       80    4.000165e+02   2.363994e+02   2.423813e+00          1
       81    1.809511e+02   2.364025e+02   2.457987e+00          1
       82    1.500336e+02   2.364029e+02   2.483427e+00          1
       83    1.885023e+02   2.364055e+02   2.508908e+00          1
       84    5.506257e+00   2.364059e+02   2.513259e+00          1
       85    1.765602e+02   2.364072e+02   2.541846e+00          1
       86    5.885255e+02   2.364094e+02   2.631268e+00          1
       87    1.525194e+02   2.364107e+02   2.647650e+00          1
       88    1.229829e+02   2.364113e+02   2.666015e+00          1
       89    1.064957e+02   2.364122e+02   2.682917e+00          1
       90    5.485184e+02   2.364132e+02   2.781359e+00          1
       91    1.371506e+03   2.364180e+02   3.012606e+00          1
       92    3.394872e+02   2.364189e+02   3.077360e+00          1
       93    2.469901e+02   2.364203e+02   3.123294e+00          1
       94    2.280003e+02   2.364206e+02   3.155870e+00          1
       95    2.140047e+02   2.364210e+02   3.197952e+00          1
       96    5.850775e+01   2.364211e+02   3.216044e+00          1
       97    2.564934e+02   2.364224e+02   3.264339e+00          1
       98    7.000992e+01   2.364225e+02   3.283439e+00          1
       99    1.805046e+02   2.364230e+02   3.328073e+00          1
      100    9.649345e+01   2.364231e+02   3.347044e+00          1

Terminating training with status: iteration_limit
------------------------------------------------------------------</code></pre><h2 id="Simulating-the-policy-1"><a class="docs-heading-anchor" href="#Simulating-the-policy-1">Simulating the policy</a><a class="docs-heading-anchor-permalink" href="#Simulating-the-policy-1" title="Permalink"></a></h2><p>After training, we can simulate the policy using <a href="../../apireference/#SDDP.simulate"><code>SDDP.simulate</code></a>.</p><pre><code class="language-julia">sims = SDDP.simulate(model, 100, [:g_t])
mu = round(mean([s[1][:g_t] for s in sims]), digits = 2)
println(&quot;On average, $(mu) units of thermal are used in the first stage.&quot;)</code></pre><pre><code class="language-none">On average, 2.08 units of thermal are used in the first stage.</code></pre><h2 id="Extracting-the-water-values-1"><a class="docs-heading-anchor" href="#Extracting-the-water-values-1">Extracting the water values</a><a class="docs-heading-anchor-permalink" href="#Extracting-the-water-values-1" title="Permalink"></a></h2><p>Finally, we can use <a href="../../apireference/#SDDP.ValueFunction"><code>SDDP.ValueFunction</code></a> and <a href="../../apireference/#SDDP.evaluate"><code>SDDP.evaluate</code></a> to obtain and evaluate the value function at different points in the state-space. Note that since we are minimizing, the price has a negative sign: each additional unit of water leads to a decrease in the the expected long-run cost.</p><pre><code class="language-julia">V = SDDP.ValueFunction(model[1])
cost, price = SDDP.evaluate(V, x = 10)</code></pre><pre><code class="language-none">(233.5378216895768, Dict(:x=&gt;-0.66027))</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../tutorial/13_integrality/">« Advanced III: integrality</a><a class="docs-footer-nextpage" href="../the_farmers_problem/">The farmer&#39;s problem »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 29 January 2020 19:51">Wednesday 29 January 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
