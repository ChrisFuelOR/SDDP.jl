<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Choose a stopping rule · SDDP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../logo.ico" rel="icon" type="image/x-icon"/></head><body><nav class="toc"><a href="../../"><img class="logo" src="../../assets/logo.png" alt="SDDP.jl logo"/></a><h1>SDDP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">How-to guides</span><ul><li><a class="toctext" href="../add_a_multidimensional_state_variable/">Add a multi-dimensional state variable</a></li><li><a class="toctext" href="../add_a_risk_measure/">Add a risk measure</a></li><li><a class="toctext" href="../add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="toctext" href="../add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li class="current"><a class="toctext" href>Choose a stopping rule</a><ul class="internal"><li><a class="toctext" href="#Basic-limits-1">Basic limits</a></li><li><a class="toctext" href="#Stopping-rules-1">Stopping rules</a></li></ul></li><li><a class="toctext" href="../create_a_general_policy_graph/">Create a general policy graph</a></li><li><a class="toctext" href="../debug_a_model/">Debug a model</a></li><li><a class="toctext" href="../improve_computational_performance/">Improve computational performance</a></li><li><a class="toctext" href="../simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li><li><a class="toctext" href="../upgrade_from_the_old_sddp/">Upgrade from the old SDDP.jl</a></li></ul></li><li><span class="toctext">Tutorials</span><ul><li><a class="toctext" href="../../tutorial/01_first_steps/">Basic I: first steps</a></li><li><a class="toctext" href="../../tutorial/02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="toctext" href="../../tutorial/03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="toctext" href="../../tutorial/04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="toctext" href="../../tutorial/05_plotting/">Basic V: plotting</a></li><li><a class="toctext" href="../../tutorial/06_warnings/">Basic VI: words of warning</a></li><li><a class="toctext" href="../../tutorial/11_objective_states/">Advanced I: objective states</a></li><li><a class="toctext" href="../../tutorial/12_belief_states/">Advanced II: belief states</a></li><li><a class="toctext" href="../../tutorial/13_integrality/">Advanced III: integrality</a></li></ul></li><li><span class="toctext">Examples</span><ul><li><a class="toctext" href="../../examples/the_farmers_problem/">The farmer&#39;s problem</a></li></ul></li><li><a class="toctext" href="../../apireference/">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li>How-to guides</li><li><a href>Choose a stopping rule</a></li></ul><a class="edit-page" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/guides/choose_a_stopping_rule.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Choose a stopping rule</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Choose-a-stopping-rule-1" href="#Choose-a-stopping-rule-1">Choose a stopping rule</a></h1><p>The theory of SDDP tells us that the algorithm converges to an optimal policy almost surely in a finite number of iterations. In practice, this number is very large. Therefore, we need some way of pre-emptively terminating SDDP when the solution is “good enough.” We call heuristics for pre-emptively terminating SDDP <em>stopping rules</em>.</p><h2><a class="nav-anchor" id="Basic-limits-1" href="#Basic-limits-1">Basic limits</a></h2><p>The training of an SDDP policy can be terminated after a fixed number of iterations using the <code>iteration_limit</code> keyword.</p><pre><code class="language-julia">SDDP.train(model, iteration_limit = 10)</code></pre><p>The training of an SDDP policy can be terminated after a fixed number of seconds using the <code>time_limit</code> keyword.</p><pre><code class="language-julia">SDDP.train(model, time_limit = 2.0)</code></pre><h2><a class="nav-anchor" id="Stopping-rules-1" href="#Stopping-rules-1">Stopping rules</a></h2><p>In addition to the limits provided as keyword arguments, a variety of other stopping rules are available. These can be passed to <a href="../../apireference/#SDDP.train"><code>SDDP.train</code></a> as a vector to the <code>stopping_rules</code> keyword. For example:</p><pre><code class="language-julia">SDDP.train(model, stopping_rules = [SDDP.BoundStalling(10, 1e-4)])</code></pre><p>Here are the stopping rules implemented in <code>SDDP.jl</code>:</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="SDDP.IterationLimit" href="#SDDP.IterationLimit"><code>SDDP.IterationLimit</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">IterationLimit(limit::Int)</code></pre><p>Teriminate the algorithm after <code>limit</code> number of iterations.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="SDDP.TimeLimit" href="#SDDP.TimeLimit"><code>SDDP.TimeLimit</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">TimeLimit(limit::Float64)</code></pre><p>Teriminate the algorithm after <code>limit</code> seconds of computation.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="SDDP.Statistical" href="#SDDP.Statistical"><code>SDDP.Statistical</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">Statistical(; num_replications, iteration_period = 1, z_score = 1.96,
            verbose = true)</code></pre><p>Perform an in-sample Monte Carlo simulation of the policy with <code>num_replications</code> replications every <code>iteration_period</code>s. Terminate if the deterministic bound (lower if minimizing) calls into the confidence interval for the mean of the simulated cost. If <code>verbose = true</code>, print the confidence interval.</p><p>Note that this tests assumes that the simulated values are normally distributed. In infinite horizon models, this is almost never the case. The distribution is usually closer to exponential or log-normal.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="SDDP.BoundStalling" href="#SDDP.BoundStalling"><code>SDDP.BoundStalling</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">BoundStalling(num_previous_iterations::Int, tolerance::Float64)</code></pre><p>Teriminate the algorithm once the deterministic bound (lower if minimizing, upper if maximizing) fails to improve by more than <code>tolerance</code> in absolute terms for more than <code>num_previous_iterations</code> consecutve iterations.</p></div></div></section><footer><hr/><a class="previous" href="../add_noise_in_the_constraint_matrix/"><span class="direction">Previous</span><span class="title">Add noise in the constraint matrix</span></a><a class="next" href="../create_a_general_policy_graph/"><span class="direction">Next</span><span class="title">Create a general policy graph</span></a></footer></article></body></html>
