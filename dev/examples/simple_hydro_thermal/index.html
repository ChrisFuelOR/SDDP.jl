<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Hydro-thermal scheduling · SDDP.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../logo.ico" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SDDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SDDP.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">How-to guides</span><ul><li><a class="tocitem" href="../../guides/add_a_multidimensional_state_variable/">Add a multi-dimensional state variable</a></li><li><a class="tocitem" href="../../guides/add_a_risk_measure/">Add a risk measure</a></li><li><a class="tocitem" href="../../guides/add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="tocitem" href="../../guides/add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li><a class="tocitem" href="../../guides/choose_a_stopping_rule/">Choose a stopping rule</a></li><li><a class="tocitem" href="../../guides/create_a_general_policy_graph/">Create a general policy graph</a></li><li><a class="tocitem" href="../../guides/debug_a_model/">Debug a model</a></li><li><a class="tocitem" href="../../guides/improve_computational_performance/">Improve computational performance</a></li><li><a class="tocitem" href="../../guides/simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li><li><a class="tocitem" href="../../guides/upgrade_from_the_old_sddp/">Upgrade from the old SDDP.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorial/01_first_steps/">Basic I: first steps</a></li><li><a class="tocitem" href="../../tutorial/02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="tocitem" href="../../tutorial/03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="tocitem" href="../../tutorial/04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="tocitem" href="../../tutorial/05_plotting/">Basic V: plotting</a></li><li><a class="tocitem" href="../../tutorial/06_warnings/">Basic VI: words of warning</a></li><li><a class="tocitem" href="../../tutorial/11_objective_states/">Advanced I: objective states</a></li><li><a class="tocitem" href="../../tutorial/12_belief_states/">Advanced II: belief states</a></li><li><a class="tocitem" href="../../tutorial/13_integrality/">Advanced III: integrality</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Hydro-thermal scheduling</a><ul class="internal"><li><a class="tocitem" href="#Problem-Description-1"><span>Problem Description</span></a></li><li><a class="tocitem" href="#Importing-packages-1"><span>Importing packages</span></a></li><li><a class="tocitem" href="#Constructing-the-policy-graph-1"><span>Constructing the policy graph</span></a></li><li><a class="tocitem" href="#Constructing-the-model-1"><span>Constructing the model</span></a></li><li><a class="tocitem" href="#Training-the-policy-1"><span>Training the policy</span></a></li><li><a class="tocitem" href="#Simulating-the-policy-1"><span>Simulating the policy</span></a></li><li><a class="tocitem" href="#Extracting-the-water-values-1"><span>Extracting the water values</span></a></li></ul></li><li><a class="tocitem" href="../the_farmers_problem/">The farmer&#39;s problem</a></li></ul></li><li><a class="tocitem" href="../../apireference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Hydro-thermal scheduling</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Hydro-thermal scheduling</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/examples/simple_hydro_thermal.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Hydro-thermal-scheduling-1"><a class="docs-heading-anchor" href="#Hydro-thermal-scheduling-1">Hydro-thermal scheduling</a><a class="docs-heading-anchor-permalink" href="#Hydro-thermal-scheduling-1" title="Permalink"></a></h1><h2 id="Problem-Description-1"><a class="docs-heading-anchor" href="#Problem-Description-1">Problem Description</a><a class="docs-heading-anchor-permalink" href="#Problem-Description-1" title="Permalink"></a></h2><p>In a hydro-thermal problem, the agent controls a hydro-electric generator and reservoir. Each time period, they need to choose a generation quantity from thermal <code>g_t</code>, and hydro <code>g_h</code>, in order to meed demand <code>w_d</code>, which is a stagewise-independent random variable. The state variable, <code>x</code>, is the quantity of water in the reservoir at the start of each time period, and it has a minimum level of 5 units and a maximum level of 15 units. We assume that there are 10 units of water in the reservoir at the start of time, so that <code>x_0 = 10</code>. The state-variable is connected through time by the water balance constraint: <code>x.out = x.in - g_t - s + w_i,</code> where <code>x.out</code> is the quantity of water at the end of the time period, <code>x.in</code> is the quantity of water at the start of the time period, <code>s</code> is the quantity of water spilled from the reservoir, and <code>w_i</code> is a stagewise-independent random variable that represents the inflow into the reservoir during the time period.</p><p>We assume that there are three stages, <code>t=1, 2, 3</code>, representing summer-fall, winter, and spring, and that we are solving this problem in an infinite-horizon setting with a discount factor of <code>0.95</code>.</p><p>In each stage, the agent incurs the cost of spillage, plus the cost of thermal generation. We assume that the cost of thermal generation is dependent on the stage <code>t = 1, 2, 3</code>, and that in each stage, <code>w</code> is drawn from the set <code>(w_i, w_d) = {(0, 7.5), (3, 5), (10, 2.5)}</code> with equal probability.</p><h2 id="Importing-packages-1"><a class="docs-heading-anchor" href="#Importing-packages-1">Importing packages</a><a class="docs-heading-anchor-permalink" href="#Importing-packages-1" title="Permalink"></a></h2><p>For this example, in addition to <code>SDDP</code>, we need <code>GLPK</code> as a solver and <code>Statisitics</code> to compute the mean of our simulations.</p><pre><code class="language-julia">using GLPK
using SDDP
using Statistics</code></pre><h2 id="Constructing-the-policy-graph-1"><a class="docs-heading-anchor" href="#Constructing-the-policy-graph-1">Constructing the policy graph</a><a class="docs-heading-anchor-permalink" href="#Constructing-the-policy-graph-1" title="Permalink"></a></h2><p>There are three stages in our problem, so we construct a linear policy graph with three stages using <a href="../../apireference/#SDDP.LinearGraph"><code>SDDP.LinearGraph</code></a>:</p><pre><code class="language-julia">graph = SDDP.LinearGraph(3)</code></pre><pre><code class="language-none">Root
 0
Nodes
 1
 2
 3
Arcs
 0 =&gt; 1 w.p. 1.0
 1 =&gt; 2 w.p. 1.0
 2 =&gt; 3 w.p. 1.0
</code></pre><p>Then, because we want to solve an infinite-horizon problem, we add an additional edge between node <code>3</code> and node <code>1</code> with probability <code>0.95</code>:</p><pre><code class="language-julia">SDDP.add_edge(graph, 3 =&gt; 1, 0.95)</code></pre><h2 id="Constructing-the-model-1"><a class="docs-heading-anchor" href="#Constructing-the-model-1">Constructing the model</a><a class="docs-heading-anchor-permalink" href="#Constructing-the-model-1" title="Permalink"></a></h2><p>Much of the macro code (i.e., lines starting with <code>@</code>) in the first part of the following should be familiar to users of JuMP.</p><p>Inside the <code>do-end</code> block (if this isn&#39;t familiar, see <a href="../../tutorial/01_first_steps/#What&#39;s-this-weird-do-syntax?-1">What&#39;s this weird <code>do</code> syntax?</a>), <code>sp</code> is a standard JuMP model, and <code>t</code> is an index for the state variable that will be called with <code>t = 1, 2, 3</code>.</p><p>The state variable <code>x</code>, constructed by passing the <code>SDDP.State</code> tag to <code>@variable</code> is actually a Julia struct with two fields: <code>x.in</code> and <code>x.out</code> corresponding to the incoming and outgoing state variables respectively. Both <code>x.in</code> and <code>x.out</code> are standard JuMP variables. The <code>initial_value</code> keyword provides the value of the state variable in the root node (i.e., <code>x_0</code>).</p><p>Compared to a JuMP model, one key difference is that we use <a href="../../apireference/#SDDP.@stageobjective"><code>@stageobjective</code></a> instead of <code>@objective</code>. The <a href="../../apireference/#SDDP.parameterize"><code>SDDP.parameterize</code></a> function takes a list of supports for <code>w</code> and parameterizes the JuMP model <code>sp</code> by setting the right-hand sides of the appropriate constraints (note how the constraints initially have a right-hand side of <code>0</code>). By default, it is assumed that the realizations have uniform probability, but a probability mass vector can also be provided.</p><pre><code class="language-julia">model = SDDP.PolicyGraph(
  graph, sense = :Min, lower_bound = 0.0, optimizer = with_optimizer(GLPK.Optimizer)
) do sp, t
  @variable(sp, 5 &lt;= x &lt;= 15, SDDP.State, initial_value = 10)
  @variable(sp, g_t &gt;= 0)
  @variable(sp, g_h &gt;= 0)
  @variable(sp, s &gt;= 0)
  @constraint(sp, balance, x.out - x.in + g_h + s == 0)
  @constraint(sp, demand, g_h + g_t == 0)
  @stageobjective(sp, s + t * g_t)
  SDDP.parameterize(sp, [[0, 7.5], [3, 5], [10, 2.5]]) do w
    set_normalized_rhs(balance, w[1])
    set_normalized_rhs(demand, w[2])
  end
end</code></pre><pre><code class="language-none">A policy graph with 3 nodes.
 Node indices: 1, 2, 3
</code></pre><h2 id="Training-the-policy-1"><a class="docs-heading-anchor" href="#Training-the-policy-1">Training the policy</a><a class="docs-heading-anchor-permalink" href="#Training-the-policy-1" title="Permalink"></a></h2><p>Once a model has been constructed, the next step is to train the policy. This can be achieved using <a href="../../apireference/#SDDP.train"><code>SDDP.train</code></a>. There are many options that can be passed, but <code>iteration_limit</code> terminates the training after the prescribed number of SDDP iterations.</p><pre><code class="language-julia">SDDP.train(model, iteration_limit = 100)</code></pre><pre><code class="language-none">------------------------------------------------------------------
                SDDP.jl (c) Oscar Dowson, 2017-20

Numerical stability report
  Non-zero Matrix range     [1e+00, 1e+00]
  Non-zero Objective range  [1e+00, 3e+00]
  Non-zero Bounds range     [5e+00, 2e+01]
  Non-zero RHS range        [3e+00, 1e+01]
No problems detected

Solver: serial mode

 Iteration    Simulation       Bound         Time (s)    Proc. ID
        1    4.650000e+01   1.618715e+01   2.820089e-01          1
        2    1.384850e+02   5.956755e+01   2.864468e-01          1
        3    6.030000e+02   1.444029e+02   3.181920e-01          1
        4    7.490003e+02   1.811116e+02   3.443398e-01          1
        5    3.145361e+02   1.941850e+02   3.578169e-01          1
        6    1.285832e+02   1.967711e+02   3.625159e-01          1
        7    1.958087e+02   1.997705e+02   3.693979e-01          1
        8    3.714826e+02   2.092189e+02   3.883150e-01          1
        9    5.256775e+01   2.105142e+02   3.940020e-01          1
       10    2.430000e+02   2.145219e+02   4.059248e-01          1
       11    6.472860e+02   2.218530e+02   4.381468e-01          1
       12    9.784439e+01   2.231794e+02   4.450219e-01          1
       13    3.495119e+02   2.259460e+02   4.828598e-01          1
       14    1.954692e+01   2.259460e+02   4.844990e-01          1
       15    6.992058e+01   2.261896e+02   4.880998e-01          1
       16    2.863016e+01   2.265913e+02   4.908478e-01          1
       17    2.500000e+00   2.267228e+02   4.918129e-01          1
       18    2.003858e+02   2.276493e+02   5.040619e-01          1
       19    1.438102e+02   2.280286e+02   5.162449e-01          1
       20    1.137676e+02   2.286699e+02   5.256178e-01          1
       21    2.684705e+02   2.293652e+02   5.444169e-01          1
       22    5.759294e+02   2.315002e+02   5.858099e-01          1
       23    3.084346e+02   2.320273e+02   6.078110e-01          1
       24    1.638227e+02   2.324841e+02   6.193409e-01          1
       25    4.388189e+02   2.332265e+02   6.528978e-01          1
       26    2.336338e+02   2.335010e+02   6.711800e-01          1
       27    3.217821e+02   2.341478e+02   7.032878e-01          1
       28    1.211648e+02   2.342079e+02   7.103980e-01          1
       29    2.953834e+01   2.342167e+02   7.136848e-01          1
       30    2.518648e+01   2.343275e+02   7.320628e-01          1
       31    7.392444e+02   2.344273e+02   7.784648e-01          1
       32    5.965014e+01   2.345756e+02   7.830720e-01          1
       33    5.464692e+02   2.347790e+02   8.248780e-01          1
       34    3.029333e+02   2.350641e+02   8.530519e-01          1
       35    4.340794e+01   2.351079e+02   8.576460e-01          1
       36    1.268362e+02   2.351598e+02   8.734899e-01          1
       37    3.283496e+02   2.353573e+02   9.015498e-01          1
       38    4.000000e+01   2.353763e+02   9.041009e-01          1
       39    2.615991e+02   2.354651e+02   9.328740e-01          1
       40    7.354848e+02   2.356341e+02   1.001639e+00          1
       41    5.955561e+01   2.356539e+02   1.009004e+00          1
       42    4.419176e+02   2.358302e+02   1.074218e+00          1
       43    1.996901e+02   2.358666e+02   1.097713e+00          1
       44    3.091448e+02   2.359484e+02   1.135207e+00          1
       45    1.427003e+03   2.360433e+02   1.280447e+00          1
       46    7.902021e+01   2.360684e+02   1.289025e+00          1
       47    7.021936e+01   2.360745e+02   1.298896e+00          1
       48    8.000000e+00   2.360827e+02   1.300475e+00          1
       49    2.741755e+02   2.361211e+02   1.337783e+00          1
       50    1.573369e+02   2.361301e+02   1.349259e+00          1
       51    2.201606e+01   2.361316e+02   1.352322e+00          1
       52    1.559585e+02   2.361630e+02   1.386534e+00          1
       53    2.199435e+02   2.361730e+02   1.417878e+00          1
       54    7.794725e+01   2.361889e+02   1.431638e+00          1
       55    1.750000e+01   2.361903e+02   1.433376e+00          1
       56    6.739706e+02   2.362237e+02   1.524499e+00          1
       57    3.186749e+02   2.362476e+02   1.569838e+00          1
       58    1.174796e+02   2.362497e+02   1.586259e+00          1
       59    1.270024e+02   2.362505e+02   1.598082e+00          1
       60    4.025909e+02   2.362715e+02   1.650054e+00          1
       61    4.857928e+01   2.362788e+02   1.655168e+00          1
       62    3.758753e+02   2.362853e+02   1.703904e+00          1
       63    6.246788e+01   2.362908e+02   1.719937e+00          1
       64    7.248216e+01   2.362908e+02   1.725403e+00          1
       65    8.401932e+01   2.362934e+02   1.732730e+00          1
       66    3.255441e+02   2.363013e+02   1.811959e+00          1
       67    2.896376e+02   2.363138e+02   1.860525e+00          1
       68    6.002004e+02   2.363255e+02   1.944836e+00          1
       69    2.400307e+02   2.363365e+02   1.975125e+00          1
       70    4.830185e+02   2.363449e+02   2.062607e+00          1
       71    1.785052e+02   2.363533e+02   2.088405e+00          1
       72    6.112873e+01   2.363533e+02   2.099659e+00          1
       73    2.852169e+01   2.363564e+02   2.107022e+00          1
       74    5.890303e+02   2.363660e+02   2.204758e+00          1
       75    1.900243e+02   2.363681e+02   2.247052e+00          1
       76    4.520033e+02   2.363765e+02   2.320406e+00          1
       77    2.035564e+02   2.363778e+02   2.354542e+00          1
       78    4.015555e+02   2.363849e+02   2.416793e+00          1
       79    5.208321e+01   2.363870e+02   2.432440e+00          1
       80    5.050168e+01   2.363874e+02   2.438473e+00          1
       81    2.481739e+00   2.363893e+02   2.440631e+00          1
       82    3.974969e+02   2.363947e+02   2.511260e+00          1
       83    6.850196e+01   2.363954e+02   2.518631e+00          1
       84    6.949884e+01   2.363968e+02   2.550409e+00          1
       85    8.098482e+01   2.363990e+02   2.568955e+00          1
       86    6.329721e+02   2.364016e+02   2.663819e+00          1
       87    2.230129e+02   2.364059e+02   2.708939e+00          1
       88    8.870589e+02   2.364085e+02   2.890450e+00          1
       89    1.160040e+02   2.364115e+02   2.918327e+00          1
       90    4.604657e+02   2.364125e+02   3.001408e+00          1
       91    1.074864e+02   2.364144e+02   3.026860e+00          1
       92    5.199310e+01   2.364144e+02   3.037366e+00          1
       93    9.289975e+02   2.364167e+02   3.241399e+00          1
       94    1.720225e+02   2.364182e+02   3.266564e+00          1
       95    9.855295e+02   2.364198e+02   3.505650e+00          1
       96    1.449416e+01   2.364206e+02   3.513515e+00          1
       97    5.350014e+01   2.364207e+02   3.523487e+00          1
       98    1.900129e+01   2.364209e+02   3.528473e+00          1
       99    4.160000e+02   2.364225e+02   3.597280e+00          1
      100    8.900465e+01   2.364225e+02   3.614427e+00          1

Terminating training with status: iteration_limit
------------------------------------------------------------------</code></pre><h2 id="Simulating-the-policy-1"><a class="docs-heading-anchor" href="#Simulating-the-policy-1">Simulating the policy</a><a class="docs-heading-anchor-permalink" href="#Simulating-the-policy-1" title="Permalink"></a></h2><p>After training, we can simulate the policy using <a href="../../apireference/#SDDP.simulate"><code>SDDP.simulate</code></a>.</p><pre><code class="language-julia">sims = SDDP.simulate(model, 100, [:g_t])
mu = round(mean([s[1][:g_t] for s in sims]), digits = 2)
println(&quot;On average, $(mu) units of thermal are used in the first stage.&quot;)</code></pre><pre><code class="language-none">On average, 2.21 units of thermal are used in the first stage.</code></pre><h2 id="Extracting-the-water-values-1"><a class="docs-heading-anchor" href="#Extracting-the-water-values-1">Extracting the water values</a><a class="docs-heading-anchor-permalink" href="#Extracting-the-water-values-1" title="Permalink"></a></h2><p>Finally, we can use <a href="../../apireference/#SDDP.ValueFunction"><code>SDDP.ValueFunction</code></a> and <a href="../../apireference/#SDDP.evaluate"><code>SDDP.evaluate</code></a> to obtain and evaluate the value function at different points in the state-space. Note that since we are minimizing, the price has a negative sign: each additional unit of water leads to a decrease in the the expected long-run cost.</p><pre><code class="language-julia">V = SDDP.ValueFunction(model[1])
cost, price = SDDP.evaluate(V, x = 10)</code></pre><pre><code class="language-none">(233.53634635068522, Dict(:x=&gt;-0.65136))</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../tutorial/13_integrality/">« Advanced III: integrality</a><a class="docs-footer-nextpage" href="../the_farmers_problem/">The farmer&#39;s problem »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 23 January 2020 16:31">Thursday 23 January 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
