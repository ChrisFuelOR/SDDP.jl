<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Manual · SDDP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/><link href="assets/custom.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>SDDP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Manual</a><ul class="internal"><li><a class="toctext" href="#Overview-1">Overview</a></li><li><a class="toctext" href="#Getting-started-1">Getting started</a></li><li><a class="toctext" href="#Formulating-the-problem-1">Formulating the problem</a></li><li><a class="toctext" href="#Communicating-the-problem-to-the-solver-1">Communicating the problem to the solver</a></li><li><a class="toctext" href="#Solving-the-problem-efficiently-1">Solving the problem efficiently</a></li><li><a class="toctext" href="#Understanding-the-solution-1">Understanding the solution</a></li><li><a class="toctext" href="#Extras-for-experts-1">Extras for experts</a></li></ul></li><li><a class="toctext" href="apireference.html">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Manual</a></li></ul><a class="edit-page" href="https://github.com/odow/SDDP.jl/tree/4860ba05ab8e058eeb031cd81fff316af3938a8e/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Manual</span><a class="fa fa-bars" href="#"></a></div></header><h2><a class="nav-anchor" id="Overview-1" href="#Overview-1">Overview</a></h2><p><em>SDDP.jl - Stochastic Dual Dynamic Programming in Julia.</em></p><p>Solving a mathematical optimization problem requires four steps:</p><ol><li><p>Formulating the problem;</p></li><li><p>Communicating the problem to the solver;</p></li><li><p>Solving the problem efficiently;</p></li><li><p>Understanding the solution.</p></li></ol><p>For deterministic problems, <a href="https://github.com/JuliaOpt/JuMP.jl">JuMP.jl</a> provides a first-in-class solution to each of these steps.</p><p>SDDP.jl builds upon JuMP to provide a high-level interface to the current state-of-the-art in order to make solving large multi-stage convex stochastic optimization problems easy.</p><p>In this manual, we detail the many features of SDDP.jl through the classic example of balancing a portfolio of stocks and bonds over time.</p><h2><a class="nav-anchor" id="Getting-started-1" href="#Getting-started-1">Getting started</a></h2><p>This package is unregistered so you will need to <code>Pkg.clone</code> it as follows:</p><pre><code class="language-julia">Pkg.clone(&quot;https://github.com/odow/SDDP.jl.git&quot;)</code></pre><p>If you want to use the parallel features of SDDP.jl, you should start Julia with some worker processes (<code>julia -p N</code>), or add by running <code>julia&gt; addprocs(N)</code> in a running Julia session.</p><h2><a class="nav-anchor" id="Formulating-the-problem-1" href="#Formulating-the-problem-1">Formulating the problem</a></h2><h3><a class="nav-anchor" id="The-Asset-Management-Problem-1" href="#The-Asset-Management-Problem-1">The Asset Management Problem</a></h3><p>The goal of the asset management problem is to choose an investment portfolio that is composed of stocks and bonds in order to meet a target wealth goal at the end of the time horizon. After five, and ten years, the agent observes the portfolio and is able to re-balance their wealth between the two asset classes. As an extension to the original problem, we introduce two new random variables. The first that represents a source of additional wealth in years 5 and 10. The second is an immediate reward that the agent incurs for holding stocks at the end of years 5 and 10. This can be though of as a dividend that cannot be reinvested.</p><h2><a class="nav-anchor" id="Communicating-the-problem-to-the-solver-1" href="#Communicating-the-problem-to-the-solver-1">Communicating the problem to the solver</a></h2><p>The second step in the optimization process is communicating the problem to the solver. To do this, we are going to build each subproblem as a JuMP model, and provide some metadata that describes how the JuMP subproblems inter-relate.</p><h3><a class="nav-anchor" id="The-Model-Constructor-1" href="#The-Model-Constructor-1">The Model Constructor</a></h3><p>The core type of SDDP.jl is the <code>SDDPModel</code> object. It can be constructed with</p><pre><code class="language-julia">m = SDDPModel( ... metadata as keyword arguments ... ) do sp, t, i
    ... JuMP subproblem definition ...
end</code></pre><p>We draw the readers attention to three sections in the SDDPModel constructor.</p><h3><a class="nav-anchor" id="State-Variables-1" href="#State-Variables-1">State Variables</a></h3><p>We can define a new state variable in the stage problem <code>sp</code> using the <code>@state</code> macro:</p><pre><code class="language-julia">@state(sp, x &gt;= 0.5, x0==1)</code></pre><p>We can also use indexing just as we would in a JuMP <code>@variable</code> macro:</p><pre><code class="language-julia">X0 = [3.0, 2.0]
@state(sp, x[i=1:2], x0==X0[i])</code></pre><p>In this case, both <code>x</code> and <code>x0</code> are JuMP dicts that can be indexed with the keys <code>1</code> and <code>2</code>. All the indices must be specified in the second argument, but they can be referred to in the third argument. The indexing of <code>x0</code> will be identical to that of <code>x.</code></p><p>There is also a plural version of the <code>@state</code> macro</p><pre><code class="language-julia">@states(sp, begin
    x &gt;= 0.0, x0==1
    y &gt;= 0.0, y0==1
end)</code></pre><h3><a class="nav-anchor" id="Standard-JuMP-machinery-1" href="#Standard-JuMP-machinery-1">Standard JuMP machinery</a></h3><p>Remember that <code>sp</code> is just a normal JuMP model, and so (almost) anything you can do in JuMP, you can do in SDDP.jl. The one exception is the objective, which we detail in the next section.</p><p>However,, control variables are just normal JuMP variables and can be created using <code>@variable</code> or <code>@variables</code>. Dynamical constraints, and feasiblity sets can be specified using <code>@constraint</code> or <code>@constraints</code>.</p><h3><a class="nav-anchor" id="The-stage-objective-1" href="#The-stage-objective-1">The stage objective</a></h3><pre><code class="language-julia">@stageobjective(sp, obj)</code></pre><pre><code class="language-julia">@stageobjective(sp, kw=realizations, obj)
setnoiseprobability!(sp, [0.2, 0.3, 0.5])</code></pre><h3><a class="nav-anchor" id="Dynamics-with-Linear-Noise-1" href="#Dynamics-with-Linear-Noise-1">Dynamics with Linear Noise</a></h3><pre><code class="language-julia">@rhsnoise(sp, w=[1,2,3], x &lt;= w)
setnoiseprobability!(sp, [0.2, 0.3, 0.5])</code></pre><h3><a class="nav-anchor" id="Asset-Management-Example-1" href="#Asset-Management-Example-1">Asset Management Example</a></h3><p>We now have all the information necessary to define the Asset Management example in SDDP.jl:</p><pre><code class="language-julia">using SDDP, JuMP, Clp

m = SDDPModel(
               # we are minimizing
                sense = :Min,
               # there are 4 stages
               stages = 4,
               # a large negative value
      objective_bound = -1000.0,
               # a MathOptBase compatible solver
               solver = ClpSolver(),
               # transition probabilities of the lattice
    markov_transition = Array{Float64, 2}[
                        [1.0]&#39;,
                        [0.5 0.5],
                        [0.5 0.5; 0.5 0.5],
                        [0.5 0.5; 0.5 0.5]
                    ],
               # risk measures for each stage
         risk_measure = [
                        Expectation(),
                        Expectation(),
                        NestedAVaR(lambda = 0.5, beta=0.5),
                        Expectation()
                    ]
                            ) do sp, t, i
    # Data used in the problem
    ωs = [1.25, 1.06]
    ωb = [1.14, 1.12]
    Φ  = [-1, 5]
    Ψ  = [0.02, 0.0]

    # state variables
    @states(sp, begin
        xs &gt;= 0, xsbar==0
        xb &gt;= 0, xbbar==0
    end)

    if t == 1 # we can switch based on the stage
        # a constraint without noise
        @constraint(sp, xs + xb == 55 + xsbar + xbbar)
        # an objective without noise
        @stageobjective(sp, 0)
    elseif t == 2 || t == 3
        # a constraint with noisein the RHS
        @rhsnoise(sp, φ=Φ, ωs[i] * xsbar + ωb[i] * xbbar + φ == xs + xb)
        # an objective with noise
        @stageobjective(sp, ψ = Ψ, -ψ * xs)
        # noise will be sampled as (Φ[1], Ψ[1]) w.p. 0.6, (Φ[2], Ψ[2]) w.p. 0.4
        setnoiseprobability!(sp, [0.6, 0.4])
    else # when t == 4
        # some control variables
        @variable(sp, u &gt;= 0)
        @variable(sp, v &gt;= 0)
        # dynamics constraint
        @constraint(sp, ωs[i] * xsbar + ωb[i] * xbbar + u - v == 80)
        # an objective without noise
        @stageobjective(sp, 4u - v)
    end
end</code></pre><h2><a class="nav-anchor" id="Solving-the-problem-efficiently-1" href="#Solving-the-problem-efficiently-1">Solving the problem efficiently</a></h2><h2><a class="nav-anchor" id="Understanding-the-solution-1" href="#Understanding-the-solution-1">Understanding the solution</a></h2><h2><a class="nav-anchor" id="Extras-for-experts-1" href="#Extras-for-experts-1">Extras for experts</a></h2><h3><a class="nav-anchor" id="New-risk-measures-1" href="#New-risk-measures-1">New risk measures</a></h3><p>SDDP.jl makes it easy to create new risk measures. First, create a new subtype of the abstract type <code>SDDP.AbstractRiskMeasure</code>:</p><pre><code class="language-julia">immutable MyNewRiskMeasure &lt;: SDDP.AbstractRiskMeasure
end</code></pre><p>Then, overload the method <code>SDDP.modifyprobability!</code> for your new type. <code>SDDP.modifyprobability!</code> has the following signature:</p><pre><code class="language-julia">SDDP.modifyprobability!(
        measure::AbstractRiskMeasure,
        riskadjusted_distribution,
        original_distribution::Vector{Float64},
        observations::Vector{Float64},
        m::SDDPModel,
        sp::JuMP.Model
)</code></pre><p>where <code>original_distribution</code> contains the risk netural probability of each outcome in <code>observations</code> occurring (so that the probability of <code>observations[i]</code> is <code>original_distribution[i]</code>). The method should modify (in-place) the elements of <code>riskadjusted_distribution</code> to represent the risk-adjusted probabilities of the distribution.</p><p>To illustrate this, we shall define the worst-case riskmeasure (which places all the probability on the worst outcome).</p><pre><code class="language-julia">immutable WorstCase &lt;: SDDP.AbstractRiskMeasure end
function SDDP.modifyprobability!(measure::WorstCase,
        riskadjusted_distribution,
        original_distribution::Vector{Float64},
        observations::Vector{Float64},
        m::SDDPModel,
        sp::JuMP.Model
    )
    if JuMP.getobjectivesense(sp) == :Min
        # if minimizing, worst is the maximum outcome
        idx = indmax(observations)
    else
        # if maximizing, worst is the minimum outcome
        idx = indmin(observations)
    end
    # zero all probabilities
    riskadjusted_distribution .= 0.0
    # set worst to 1.0
    riskadjusted_distribution[idx] = 1.0
    # return
    return nothing
end</code></pre><p>The risk measure <code>WorstCase()</code> can now be used in any SDDP model.</p><h3><a class="nav-anchor" id="New-cut-oracles-1" href="#New-cut-oracles-1">New cut oracles</a></h3><footer><hr/><a class="next" href="apireference.html"><span class="direction">Next</span><span class="title">Reference</span></a></footer></article></body></html>
